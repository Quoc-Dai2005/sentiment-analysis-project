# ðŸ“˜ PhÃ¢n TÃ­ch Cáº£m XÃºc BÃ¬nh Luáº­n Tiáº¿ng Viá»‡t (Vietnamese Sentiment Analysis)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python)
![PhoBERT](https://img.shields.io/badge/Model-PhoBERT%20Large-yellow?style=for-the-badge)
![Gradio](https://img.shields.io/badge/Gradio-UI-orange?style=for-the-badge)

<<<<<<< Updated upstream
Dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng AI tá»± Ä‘á»™ng phÃ¢n loáº¡i cáº£m xÃºc tá»« vÄƒn báº£n tiáº¿ng Viá»‡t sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n **PhoBERT**.

## ðŸ“‚ 1. Cáº¥u TrÃºc & MÃ´ Táº£ Module MÃ£ Nguá»“n

Dá»± Ã¡n bao gá»“m cÃ¡c thÃ nh pháº§n mÃ£ nguá»“n chÃ­nh sau Ä‘Ã¢y:

### ðŸ› ï¸ Module 1: Huáº¥n luyá»‡n MÃ´ hÃ¬nh (`trainer-ai.ipynb`)
ÄÃ¢y lÃ  module nÃ²ng cá»‘t (Core Engine), chá»‹u trÃ¡ch nhiá»‡m "dáº¡y" cho AI há»c tá»« dá»¯ liá»‡u.
* **Chá»©c nÄƒng:**
    1.  **Data Loading:** Äá»c dá»¯ liá»‡u tá»« file `data/comments.csv`.
    2.  **Preprocessing:** Sá»­ dá»¥ng thÆ° viá»‡n `Underthesea` Ä‘á»ƒ tÃ¡ch tá»« tiáº¿ng Viá»‡t (Word Segmentation).
    3.  **Tokenization:** MÃ£ hÃ³a vÄƒn báº£n thÃ nh dáº¡ng sá»‘ sá»­ dá»¥ng `AutoTokenizer` cá»§a PhoBERT.
    4.  **Training:** Huáº¥n luyá»‡n mÃ´ hÃ¬nh `vinai/phobert-large` vá»›i ká»¹ thuáº­t *Mixed Precision (FP16)* vÃ  *Gradient Accumulation*.
    5.  **Evaluation:** ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c, váº½ biá»ƒu Ä‘á»“ Loss vÃ  Confusion Matrix.
    6.  **Export:** LÆ°u model Ä‘Ã£ huáº¥n luyá»‡n ra thÆ° má»¥c `my_phobert_sentiment`.

### ðŸŒ Module 2: á»¨ng dá»¥ng Web (`app.py`)
ÄÃ¢y lÃ  module giao diá»‡n ngÆ°á»i dÃ¹ng (User Interface).
* **Chá»©c nÄƒng:**
    1.  **Model Loading:** Táº£i model tá»« thÆ° má»¥c `my_phobert_sentiment`.
    2.  **Inference:** Nháº­n vÄƒn báº£n -> TÃ¡ch tá»« -> Dá»± Ä‘oÃ¡n cáº£m xÃºc (TÃ­ch cá»±c/TiÃªu cá»±c/Trung láº­p).
    3.  **UI:** Hiá»ƒn thá»‹ giao diá»‡n web chat báº±ng `Gradio`.

### ðŸ“¦ Module 3: Quáº£n lÃ½ ThÆ° viá»‡n (`requirements.txt`)
* **Chá»©c nÄƒng:** Liá»‡t kÃª danh sÃ¡ch cÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t (Torch, Transformers, Gradio, Scikit-learn...).

---

## âš™ï¸ 2. HÆ°á»›ng Dáº«n CÃ i Äáº·t (Installation)

**BÆ°á»›c 1: Clone dá»± Ã¡n vá» mÃ¡y**
```bash
git clone https://github.com/Quoc-Dai2005/sentiment-analysis-project.git
cd sentiment-analysis-project
```
**BÆ°á»›c 2: Táº¡o mÃ´i trÆ°á»ng áº£o (Khuyáº¿n nghá»‹)**
```bash
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```
**BÆ°á»›c 3: CÃ i Ä‘áº·t thÆ° viá»‡n**
```bash
pip install -r requirements.txt
```
## ðŸš€ 3. HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng
* **CÃ¡ch 1: Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh (Training)**
    1. Äá»ƒ file dá»¯ liá»‡u táº¡i `data/comments.csv`.
    2. Má»Ÿ file `trainer-ai.ipynb` trong VS Code.
    3. Chá»n Run All Ä‘á»ƒ cháº¡y toÃ n bá»™ quÃ¡ trÃ¬nh train.
    4. Model má»›i sáº½ Ä‘Æ°á»£c lÆ°u vÃ o `my_phobert_sentiment`.
* **CÃ¡ch 2: Cháº¡y á»©ng dá»¥ng Demo (Web App)**
    1. Má»Ÿ Terminal táº¡i thÆ° má»¥c dá»± Ã¡n.
    2. Cháº¡y lá»‡nh:
    ```bash
    python app.py
    ```
    3. Truy cáº­p link `http://127.0.0.1:7860` trÃªn trÃ¬nh duyá»‡t.
## âš ï¸ LÆ°u Ã½ ká»¹ thuáº­t
* **YÃªu cáº§u GPU:** NÃªn train trÃªn GPU (NVIDIA) hoáº·c Kaggle/Colab Ä‘á»ƒ Ä‘áº¡t tá»‘c Ä‘á»™ tá»‘t nháº¥t.
* **Git LFS:** File model PhoBERT ráº¥t náº·ng (>1GB), khÃ´ng Ä‘Æ°á»£c upload trá»±c tiáº¿p lÃªn GitHub mÃ  nÃªn Ä‘Æ°á»£c lÆ°u cá»¥c bá»™ hoáº·c dÃ¹ng Git LFS.


=======
---

## ðŸ“‹ ThÃ´ng Tin Dá»± Ãn

- MÃ´n há»c: MAT3508 â€“ Nháº­p mÃ´n TrÃ­ tuá»‡ NhÃ¢n táº¡o
- Há»c ká»³: Há»c ká»³ 1 â€“ NÄƒm há»c 2025-2026
- TrÆ°á»ng: VNU-HUS (ÄHQG HÃ  Ná»™i â€“ TrÆ°á»ng Äáº¡i há»c Khoa há»c Tá»± nhiÃªn)
- TiÃªu Ä‘á» dá»± Ã¡n: PhÃ¢n tÃ­ch cáº£m xÃºc Ä‘Ã¡nh giÃ¡ tiáº¿ng Viá»‡t sá»­ dá»¥ng mÃ´ hÃ¬nh PhoBERT
- NgÃ y ná»™p: 30/11/2025

- BÃ¡o cÃ¡o PDF: `bao_cao_AI.pdf`
- Slide 1: `Slide_AI.pdf`
- Slide 2: `Green-Modern-Simple-Cybersecurity-Presentation.pdf`

ThÃ nh viÃªn nhÃ³m:

| Há» vÃ  tÃªn        | MÃ£ sinh viÃªn | GitHub         | ÄÃ³ng gÃ³p chÃ­nh                            |
|------------------|-------------|----------------|-------------------------------------------|
| Äá»“ng Quá»‘c Äáº¡i    | 23001513    | Quoc-Dai2005   | MÃ´ hÃ¬nh PhoBERT, huáº¥n luyá»‡n, tá»‘i Æ°u.     |
| Chu ThÃ nh DÅ©ng   | 23001506    | ChuThanhDung   | Dá»¯ liá»‡u, NLP, viáº¿t bÃ¡o cÃ¡o.              |
| Nguyá»…n Máº¡nh DÅ©ng | 23001507    | mdunglittleboi | Trá»±c quan, slide, demo Gradio, kiá»ƒm thá»­. |

---

## ðŸ“‚ 1. Cáº¥u TrÃºc & MÃ´ Táº£ Module MÃ£ Nguá»“n

.
â”œâ”€â”€ app.py # Web demo Gradio dÃ¹ng model Ä‘Ã£ huáº¥n luyá»‡n
â”œâ”€â”€ trainer-ai.ipynb # Notebook huáº¥n luyá»‡n PhoBERT trÃªn dá»¯ liá»‡u Tiki
â”œâ”€â”€ bao_cao_AI.pdf # BÃ¡o cÃ¡o chÃ­nh
â”œâ”€â”€ Green-Modern-Simple-Cybersecurity-Presentation.pdf
â”œâ”€â”€ Slide_AI.pdf
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚ â””â”€â”€ comments.csv # Dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ (1â€“5 sao)
â”œâ”€â”€ my_phobert_sentiment/ # ThÆ° má»¥c model Ä‘Ã£ fine-tune (tá»± sinh sau khi train, gá»­i trong file pdf gá»­i trÃªn canvas)
â”‚ â”œâ”€â”€ config.json
â”‚ â”œâ”€â”€ pytorch_model.bin
â”‚ â”œâ”€â”€ tokenizer.json
â”‚ â””â”€â”€ ...
â””â”€â”€ README.md

text

### ðŸ› ï¸ `trainer-ai.ipynb` â€“ Huáº¥n luyá»‡n mÃ´ hÃ¬nh

- Äá»c dá»¯ liá»‡u tá»« `data/comments.csv`.
- Tiá»n xá»­ lÃ½: chuáº©n hÃ³a Unicode, lÃ m sáº¡ch vÄƒn báº£n.
- TÃ¡ch tá»« tiáº¿ng Viá»‡t báº±ng `underthesea.word_tokenize`.
- MÃ£ hÃ³a báº±ng `AutoTokenizer` cá»§a `vinai/phobert-large`.
- Chia train/test, táº¡o `Dataset` HuggingFace, cáº¥u hÃ¬nh `TrainingArguments`.
- Huáº¥n luyá»‡n vá»›i FP16, Gradient Accumulation, LR = 1e-5, 4 epoch.
- ÄÃ¡nh giÃ¡ báº±ng Accuracy, F1-macro, Confusion Matrix, ROC-AUC.
- LÆ°u model + tokenizer vÃ o `./my_phobert_sentiment`.

### ðŸŒ `app.py` â€“ á»¨ng dá»¥ng Web Gradio

- Táº£i model vÃ  tokenizer tá»« `./my_phobert_sentiment`.
- HÃ m xá»­ lÃ½:
  - Nháº­n cÃ¢u tiáº¿ng Viá»‡t thÃ´.
  - TÃ¡ch tá»« báº±ng `underthesea` (Ä‘Æ°a vá» dáº¡ng â€œgiao_hÃ ng nhanhâ€).
  - Tokenize báº±ng PhoBERT, Ä‘Æ°a qua model.
  - Tráº£ vá» nhÃ£n cáº£m xÃºc vÃ  xÃ¡c suáº¥t 3 lá»›p.
- Táº¡o giao diá»‡n Gradio vá»›i:
  - Ã” nháº­p text.
  - Hiá»ƒn thá»‹ nhÃ£n + xÃ¡c suáº¥t tá»«ng lá»›p.
  - Má»™t sá»‘ vÃ­ dá»¥ máº«u (vÃ­ dá»¥ cÃ¢u khen/chÃª/trung láº­p).
- Cháº¡y server Gradio trÃªn `http://127.0.0.1:7860`.

### ðŸ“¦ `requirements.txt`

Chá»©a cÃ¡c thÆ° viá»‡n chÃ­nh:

- torch, torchvision, torchaudio
- transformers, datasets
- underthesea
- scikit-learn
- matplotlib, seaborn
- gradio

---

## âš™ï¸ 2. HÆ°á»›ng Dáº«n CÃ i Äáº·t

1. Clone dá»± Ã¡n:

git clone https://github.com/Quoc-Dai2005/sentiment-analysis-project.git
cd sentiment-analysis-project

text

2. Táº¡o vÃ  kÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹):

python -m venv venv

Windows:
.\venv\Scripts\activate

Linux/Mac:
source venv/bin/activate

text

3. CÃ i Ä‘áº·t thÆ° viá»‡n:

pip install -r requirements.txt

text

---

## ðŸš€ 3. HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### CÃ¡ch 1 â€“ Huáº¥n luyá»‡n láº¡i PhoBERT

1. Chuáº©n bá»‹ dá»¯ liá»‡u táº¡i `data/comments.csv` (gá»“m text + rating 1â€“5).  
2. Má»Ÿ `trainer-ai.ipynb` trong VS Code / Jupyter.  
3. Cháº¡y toÃ n bá»™ notebook.  
4. Sau khi cháº¡y xong, thÆ° má»¥c `my_phobert_sentiment/` sáº½ Ä‘Æ°á»£c táº¡o vá»›i model Ä‘Ã£ fine-tune.

### CÃ¡ch 2 â€“ Cháº¡y demo web Gradio

1. Äáº£m báº£o Ä‘Ã£ cÃ³ thÆ° má»¥c `my_phobert_sentiment/` (tá»« bÆ°á»›c train hoáº·c copy tá»« nÆ¡i khÃ¡c).  
2. Má»Ÿ Terminal táº¡i thÆ° má»¥c dá»± Ã¡n, cháº¡y:

python app.py

text

3. Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p:

http://127.0.0.1:7860

text

4. Nháº­p cÃ¢u bÃ¬nh luáº­n tiáº¿ng Viá»‡t Ä‘á»ƒ há»‡ thá»‘ng dá»± Ä‘oÃ¡n cáº£m xÃºc.

---

## âš ï¸ 4. LÆ°u Ã Ká»¹ Thuáº­t

- NÃªn huáº¥n luyá»‡n trÃªn GPU (NVIDIA) hoáº·c Google Colab/Kaggle Ä‘á»ƒ trÃ¡nh thá»i gian training quÃ¡ lÃ¢u.  
- PhoBERT-Large vÃ  model fine-tune khÃ¡ náº·ng, dá»… bá»‹ lá»—i Out-of-Memory náº¿u GPU yáº¿u; hÃ£y:
  - Giá»¯ `max_length` há»£p lÃ½ (128).
  - DÃ¹ng batch size nhá» + Gradient Accumulation.
  - Báº­t FP16 nhÆ° trong notebook.  
- File model Ä‘Ã£ train cÃ³ thá»ƒ >1GB â€“ khÃ´ng upload trá»±c tiáº¿p lÃªn GitHub, Ä‘Ã£ gá»­i link google drive trong file pdf gá»­i trÃªn canvas

---

## ðŸ“š 5. TÃ i Liá»‡u Tham Kháº£o

- PhoBERT â€“ Vietnamese BERT-based Language Models.  
- HuggingFace Transformers & Datasets docs.  
- Gradio â€“ Build ML web apps in Python.  
>>>>>>> Stashed changes
