{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c4de4c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Notebook hu·∫•n luy·ªán m√¥ h√¨nh PhoBERT-Large cho b√†i to√°n ph√¢n t√≠ch c·∫£m x√∫c ti·∫øng Vi·ªát.\n",
    "\n",
    "C√°c b∆∞·ªõc ch√≠nh:\n",
    "1. Load & ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë√°nh gi√° (rating 1‚Äì5 sao) t·ª´ Tiki.\n",
    "2. T√°ch t·ª´ ti·∫øng Vi·ªát, √°nh x·∫° rating -> nh√£n c·∫£m x√∫c 3 l·ªõp.\n",
    "3. Tokenize b·∫±ng PhoBERT tokenizer, t·∫°o Dataset HuggingFace.\n",
    "4. C·∫•u h√¨nh hu·∫•n luy·ªán (FP16, Gradient Accumulation, LR=1e-5).\n",
    "5. Hu·∫•n luy·ªán, ƒë√°nh gi√° (Accuracy, F1-macro, Confusion Matrix, ROC-AUC).\n",
    "6. L∆∞u model & tokenizer ƒë·ªÉ d√πng trong app.py (demo Gradio).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89731196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from underthesea import word_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {device}\")\n",
    "\n",
    "MODEL_NAME = \"vinai/phobert-large\" \n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/comments.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Kh√¥ng t√¨m th·∫•y file {file_path}. Vui l√≤ng ki·ªÉm tra l·∫°i!\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "    df = df[['rating', 'content']].dropna()\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df.dropna(subset=['rating'], inplace=True)\n",
    "\n",
    "    def map_label(rating):\n",
    "        \"\"\"\n",
    "        √Ånh x·∫° ƒëi·ªÉm ƒë√°nh gi√° (rating 1‚Äì5 sao) sang nh√£n c·∫£m x√∫c 3 l·ªõp.\n",
    "\n",
    "        Quy ∆∞·ªõc:\n",
    "            - 1‚Äì2 sao  -> 0 (Ti√™u c·ª±c)\n",
    "            - 3 sao    -> 1 (Trung l·∫≠p)\n",
    "            - 4‚Äì5 sao  -> 2 (T√≠ch c·ª±c)\n",
    "\n",
    "        Args:\n",
    "            rating (int): ƒêi·ªÉm ƒë√°nh gi√° sao (1‚Äì5).\n",
    "\n",
    "        Returns:\n",
    "            int: Nh√£n c·∫£m x√∫c t∆∞∆°ng ·ª©ng (0, 1 ho·∫∑c 2).\n",
    "        \"\"\"\n",
    "        if rating in [4, 5]: return 2\n",
    "        if rating == 3: return 1\n",
    "        return 0\n",
    "\n",
    "    df['label'] = df['rating'].apply(map_label)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "\n",
    "    print(\"ƒêang t√°ch t·ª´ (Word Segmentation)...\")\n",
    "    df['content_seg'] = df['content'].apply(lambda x: word_tokenize(str(x), format=\"text\"))\n",
    "    # Chia train/test theo stratify ƒë·ªÉ gi·ªØ t·ªâ l·ªá c√°c l·ªõp c·∫£m x√∫c gi·ªëng nhau ·ªü c·∫£ hai t·∫≠p\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df[['content_seg', 'label']])\n",
    "    test_dataset = Dataset.from_pandas(test_df[['content_seg', 'label']])\n",
    "\n",
    "    print(f\"ƒê√£ x·ª≠ l√Ω xong. Train: {len(train_df)} - Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ƒêang t·∫£i Tokenizer: {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    M√£ h√≥a vƒÉn b·∫£n ƒë√£ t√°ch t·ª´ (`content_seg`) sang token ID cho PhoBERT.\n",
    "\n",
    "    Args:\n",
    "        examples (dict): Batch d·ªØ li·ªáu t·ª´ HuggingFace Dataset, ch·ª©a tr∆∞·ªùng 'content_seg'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Th√™m c√°c tr∆∞·ªùng 'input_ids', 'attention_mask' (v√† c√°c tr∆∞·ªùng tensor kh√°c n·∫øu c√≥).\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"content_seg\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(\"ƒêang m√£ h√≥a d·ªØ li·ªáu...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "print(\"M√£ h√≥a xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91db9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ƒêang t·∫£i Model: {MODEL_NAME}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√° ch√≠nh cho m√¥ h√¨nh ph√¢n lo·∫°i c·∫£m x√∫c.\n",
    "\n",
    "    Args:\n",
    "        eval_pred (Tuple[np.ndarray, np.ndarray]):\n",
    "            - logits: ma tr·∫≠n (N, num_labels) ch·ª©a ƒëi·ªÉm d·ª± ƒëo√°n.\n",
    "            - labels: vector nh√£n th·∫≠t.\n",
    "\n",
    "    Returns:\n",
    "        dict: C√°c ch·ªâ s·ªë ƒë√°nh gi√°, bao g·ªìm:\n",
    "            - 'accuracy': ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ.\n",
    "            - 'f1_macro': F1 trung b√¨nh macro tr√™n 3 l·ªõp.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
    "# Gradient Accumulation:\n",
    "# - per_device_train_batch_size = 4\n",
    "# - gradient_accumulation_steps = 4\n",
    "# => batch size hi·ªáu d·ª•ng = 4 * 4 = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_phobert\",\n",
    "    num_train_epochs=4,             \n",
    "    per_device_train_batch_size=4,   \n",
    "    gradient_accumulation_steps=4,   \n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,     \n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\",                \n",
    "    no_cuda=False if torch.cuda.is_available() else True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"ƒê√£ c·∫•u h√¨nh xong Trainer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN...\")\n",
    "trainer.train()\n",
    "print(\"Hu·∫•n luy·ªán ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ƒêang t√≠nh to√°n v√† v·∫Ω bi·ªÉu ƒë·ªì...\")\n",
    "\n",
    "history = trainer.state.log_history\n",
    "train_loss = [x['loss'] for x in history if 'loss' in x]\n",
    "eval_f1 = [x['eval_f1_macro'] for x in history if 'eval_f1_macro' in x]\n",
    "\n",
    "preds_output = trainer.predict(tokenized_test)\n",
    "logits = preds_output.predictions\n",
    "y_true = preds_output.label_ids\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "y_prob = torch.nn.functional.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "\n",
    "target_names = ['Negative üò°', 'Neutral üòê', 'Positive üòç']\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(train_loss, label='Train Loss', color='tab:blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(eval_f1, label='Val F1-Macro', color='tab:green', marker='o')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Th·ª±c t·∫ø')\n",
    "plt.xlabel('D·ª± ƒëo√°n')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "y_test_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "n_classes = 3\n",
    "colors = cycle(['#ff7f0e', '#2ca02c', '#1f77b4'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{target_names[i]} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    plt.plot(recall, precision, color=color, lw=2, label=f'{target_names[i]}')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "max_probs = np.max(y_prob, axis=1)\n",
    "correct_indices = np.where(y_pred == y_true)[0]\n",
    "incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "plt.hist(max_probs[correct_indices], bins=20, color='green', alpha=0.5, label='ƒê√∫ng')\n",
    "plt.hist(max_probs[incorrect_indices], bins=20, color='red', alpha=0.5, label='Sai')\n",
    "plt.title('Confidence Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u model v√† tokenizer ƒë·ªÉ d√πng l·∫°i trong app.py (demo Gradio)\n",
    "save_path = \"./my-phobert-sentiment\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"ƒê√£ l∆∞u model th√†nh c√¥ng t·∫°i: {save_path}\")\n",
    "print(\"B·∫°n c√≥ th·ªÉ ch·∫°y file 'app.py' ƒë·ªÉ s·ª≠ d·ª•ng model n√†y!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
