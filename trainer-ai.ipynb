{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89731196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from underthesea import word_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {device}\")\n",
    "\n",
    "MODEL_NAME = \"vinai/phobert-large\" \n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/comments.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Kh√¥ng t√¨m th·∫•y file {file_path}. Vui l√≤ng ki·ªÉm tra l·∫°i!\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "    df = df[['rating', 'content']].dropna()\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df.dropna(subset=['rating'], inplace=True)\n",
    "\n",
    "    def map_label(rating):\n",
    "        if rating in [4, 5]: return 2\n",
    "        if rating == 3: return 1\n",
    "        return 0\n",
    "\n",
    "    df['label'] = df['rating'].apply(map_label)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "\n",
    "    print(\"ƒêang t√°ch t·ª´ (Word Segmentation)...\")\n",
    "    df['content_seg'] = df['content'].apply(lambda x: word_tokenize(str(x), format=\"text\"))\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df[['content_seg', 'label']])\n",
    "    test_dataset = Dataset.from_pandas(test_df[['content_seg', 'label']])\n",
    "\n",
    "    print(f\"ƒê√£ x·ª≠ l√Ω xong. Train: {len(train_df)} - Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ƒêang t·∫£i Tokenizer: {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"content_seg\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(\"ƒêang m√£ h√≥a d·ªØ li·ªáu...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "print(\"M√£ h√≥a xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91db9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ƒêang t·∫£i Model: {MODEL_NAME}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_phobert\",\n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=4,   \n",
    "    gradient_accumulation_steps=4,   \n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,     \n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\",                \n",
    "    no_cuda=False if torch.cuda.is_available() else True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"ƒê√£ c·∫•u h√¨nh xong Trainer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN...\")\n",
    "trainer.train()\n",
    "print(\"Hu·∫•n luy·ªán ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ƒêang t√≠nh to√°n v√† v·∫Ω bi·ªÉu ƒë·ªì...\")\n",
    "\n",
    "history = trainer.state.log_history\n",
    "train_loss = [x['loss'] for x in history if 'loss' in x]\n",
    "eval_f1 = [x['eval_f1_macro'] for x in history if 'eval_f1_macro' in x]\n",
    "\n",
    "preds_output = trainer.predict(tokenized_test)\n",
    "logits = preds_output.predictions\n",
    "y_true = preds_output.label_ids\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "y_prob = torch.nn.functional.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "\n",
    "target_names = ['Negative üò°', 'Neutral üòê', 'Positive üòç']\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(train_loss, label='Train Loss', color='tab:blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(eval_f1, label='Val F1-Macro', color='tab:green', marker='o')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Th·ª±c t·∫ø')\n",
    "plt.xlabel('D·ª± ƒëo√°n')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "y_test_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "n_classes = 3\n",
    "colors = cycle(['#ff7f0e', '#2ca02c', '#1f77b4'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{target_names[i]} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    plt.plot(recall, precision, color=color, lw=2, label=f'{target_names[i]}')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "max_probs = np.max(y_prob, axis=1)\n",
    "correct_indices = np.where(y_pred == y_true)[0]\n",
    "incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "plt.hist(max_probs[correct_indices], bins=20, color='green', alpha=0.5, label='ƒê√∫ng')\n",
    "plt.hist(max_probs[incorrect_indices], bins=20, color='red', alpha=0.5, label='Sai')\n",
    "plt.title('Confidence Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./my-phobert-sentiment\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"ƒê√£ l∆∞u model th√†nh c√¥ng t·∫°i: {save_path}\")\n",
    "print(\"B·∫°n c√≥ th·ªÉ ch·∫°y file 'app.py' ƒë·ªÉ s·ª≠ d·ª•ng model n√†y!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
