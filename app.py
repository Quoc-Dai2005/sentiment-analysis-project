import os
import torch
import gradio as gr
from underthesea import word_tokenize
from transformers import AutoTokenizer, AutoModelForSequenceClassification


MODEL_PATH = "./my_phobert_sentiment"

if not os.path.exists(MODEL_PATH):
    print(f"Lá»–I: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c model táº¡i '{MODEL_PATH}'.")
    print("Vui lÃ²ng cháº¡y file train trÆ°á»›c Ä‘á»ƒ lÆ°u model, hoáº·c chá»‰nh láº¡i Ä‘Æ°á»ng dáº«n.")
    exit()

def get_device():
    if torch.cuda.is_available():
        return torch.device("cuda")
    elif torch.backends.mps.is_available():
        return torch.device("mps")
    else:
        return torch.device("cpu")

device = get_device()
print(f"Äang cháº¡y á»©ng dá»¥ng trÃªn thiáº¿t bá»‹: {device}")

print("Äang táº£i model vÃ  tokenizer... Vui lÃ²ng chá»!")
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)
    print("âœ… Táº£i model thÃ nh cÃ´ng!")
except Exception as e:
    print(f"Lá»—i khi táº£i model: {e}")
    exit()

def predict_sentiment(text):
    if not text:
        return None
    
    text_seg = word_tokenize(text, format="text")
    
    inputs = tokenizer(
        text_seg, 
        return_tensors="pt", 
        truncation=True, 
        max_length=128, 
        padding="max_length"
    ).to(device)
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1)[0].cpu().numpy()
    
    return {
        "TiÃªu cá»±c ğŸ˜¡": float(probs[0]),
        "Trung láº­p ğŸ˜": float(probs[1]),
        "TÃ­ch cá»±c ğŸ˜": float(probs[2])
    }

iface = gr.Interface(
    fn=predict_sentiment,
    inputs=gr.Textbox(
        lines=3, 
        placeholder="Nháº­p bÃ¬nh luáº­n vÃ o Ä‘Ã¢y (VÃ­ dá»¥: HÃ ng Ä‘áº¹p nhÆ°ng giao hÆ¡i cháº­m)...", 
        label="ğŸ“ Ná»™i dung bÃ¬nh luáº­n"
    ),
    outputs=gr.Label(num_top_classes=3, label="ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch"),
    title="ğŸ¤– AI PHÃ‚N TÃCH Cáº¢M XÃšC (PHOBERT)",
    description="""
    **MÃ´ hÃ¬nh:** PhoBERT Large (Fine-tuned)
    **Chá»©c nÄƒng:** Dá»± Ä‘oÃ¡n cáº£m xÃºc cá»§a bÃ¬nh luáº­n tiáº¿ng Viá»‡t.
    **NhÃ£n:** TÃ­ch cá»±c (Positive), Trung láº­p (Neutral), TiÃªu cá»±c (Negative).
    """,
    examples=[
        ["Giao hÃ ng siÃªu nhanh, Ä‘Ã³ng gÃ³i cáº©n tháº­n, sÃ¡ch ráº¥t Ä‘áº¹p!"],
        ["Cháº¥t lÆ°á»£ng sáº£n pháº©m quÃ¡ tá»‡, khÃ´ng bao giá» quay láº¡i."],
        ["HÃ ng táº¡m á»•n, giÃ¡ hÆ¡i cao so vá»›i cháº¥t lÆ°á»£ng."],
        ["Shop treo Ä‘áº§u dÃª bÃ¡n thá»‹t chÃ³, lá»«a Ä‘áº£o."],
        ["Má»i thá»© Ä‘á»u á»•n, shipper thÃ¢n thiá»‡n."]
    ],
    theme="default"
)

if __name__ == "__main__":
    print("ğŸŒ Äang khá»Ÿi Ä‘á»™ng Web Server...")
    iface.launch(share=False, inbrowser=True)